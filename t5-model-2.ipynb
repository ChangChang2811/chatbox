{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8570459,"sourceType":"datasetVersion","datasetId":5124510},{"sourceId":8570512,"sourceType":"datasetVersion","datasetId":5124554}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration  \n\nfrom transformers import AdamW\nimport pandas as pd\nimport torch\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom torch.nn.utils.rnn import pad_sequence\n# from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n\npl.seed_everything(100)\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-31T12:58:16.523931Z","iopub.execute_input":"2024-05-31T12:58:16.524338Z","iopub.status.idle":"2024-05-31T12:58:16.532820Z","shell.execute_reply.started":"2024-05-31T12:58:16.524302Z","shell.execute_reply":"2024-05-31T12:58:16.531773Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/dataset2/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv')\ndata.drop(columns=['flags'],inplace=True)\ndata.drop(columns=['category'],inplace=True)\ndata.drop(columns=['intent'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:21.370849Z","iopub.execute_input":"2024-05-31T13:00:21.371564Z","iopub.status.idle":"2024-05-31T13:00:21.866789Z","shell.execute_reply.started":"2024-05-31T13:00:21.371500Z","shell.execute_reply":"2024-05-31T13:00:21.865911Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(\"No of rows:\" ,data)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:24.249057Z","iopub.execute_input":"2024-05-31T13:00:24.249829Z","iopub.status.idle":"2024-05-31T13:00:24.258168Z","shell.execute_reply.started":"2024-05-31T13:00:24.249790Z","shell.execute_reply":"2024-05-31T13:00:24.256855Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"No of rows:                                                 question  \\\n0       question about cancelling order {{Order Number}}   \n1      i have a question about cancelling oorder {{Or...   \n2        i need help cancelling puchase {{Order Number}}   \n3             I need to cancel purchase {{Order Number}}   \n4      I cannot afford this order, cancel purchase {{...   \n...                                                  ...   \n26867  I am waiting for a rebate of {{Refund Amount}}...   \n26868  how to see if there is anything wrong with my ...   \n26869  I'm waiting for a reimbjrsement of {{Currency ...   \n26870  I don't know what to do to see my reimbursemen...   \n26871  I need to know if there is anything new on the...   \n\n                                                  answer  \n0      I've understood you have a question regarding ...  \n1      I've been informed that you have a question ab...  \n2      I can sense that you're seeking assistance wit...  \n3      I understood that you need assistance with can...  \n4      I'm sensitive to the fact that you're facing f...  \n...                                                  ...  \n26867  Thank you for sharing your situation regarding...  \n26868  Ensuring the accuracy of your restitution is o...  \n26869  Firstly, I genuinely understand the importance...  \n26870  I've understood you're unsure about how to che...  \n26871  It's completely understandable that you want t...  \n\n[26872 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nINPUT_MAX_LEN = 128 #input length\nOUTPUT_MAX_LEN = 128 # output length\nTRAIN_BATCH_SIZE = 8 # batch size of training\nVAL_BATCH_SIZE = 2 # batch size for validation\nEPOCHS = 10 # number of epoch","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:29.355451Z","iopub.execute_input":"2024-05-31T13:00:29.356447Z","iopub.status.idle":"2024-05-31T13:00:29.407111Z","shell.execute_reply.started":"2024-05-31T13:00:29.356409Z","shell.execute_reply":"2024-05-31T13:00:29.405763Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = \"t5-base\"\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME, model_max_length=512)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:31.900275Z","iopub.execute_input":"2024-05-31T13:00:31.901578Z","iopub.status.idle":"2024-05-31T13:00:34.960225Z","shell.execute_reply.started":"2024-05-31T13:00:31.901508Z","shell.execute_reply":"2024-05-31T13:00:34.958973Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"spiece.model\";:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b94d587e73422292d293e11c357d6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"config.json\";:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8094b509ae15436cad04a90646f26d09"}},"metadata":{}}]},{"cell_type":"markdown","source":"Example of how T5 Tokenizer actually work.","metadata":{}},{"cell_type":"code","source":"text = \"Hello, how are you today?\"    # assume the text that is to be tokenized \n\ninput_tokenize = tokenizer( \n             text,\n            add_special_tokens=True,        #Add Special tokens like [CLS] and [SEP]\n            max_length=128,\n            padding = 'max_length',         #for padding to max_length for equal sequence length\n            truncation = True,              #truncate the text if it is greater than max_length\n            return_attention_mask=True,     #will return attention mask\n            return_tensors=\"pt\"             #return tensor formate\n        )","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:36.549334Z","iopub.execute_input":"2024-05-31T13:00:36.550344Z","iopub.status.idle":"2024-05-31T13:00:36.557277Z","shell.execute_reply.started":"2024-05-31T13:00:36.550298Z","shell.execute_reply":"2024-05-31T13:00:36.556103Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class T5Dataset:\n    \n  def __init__(self,question,answer):   \n    \n    self.question = question\n    self.answer = answer\n    self.tokenizer = tokenizer\n    self.input_max_len = INPUT_MAX_LEN\n    self.output_max_len = OUTPUT_MAX_LEN\n  \n  def __len__(self):                      # This method retrives the number of item from the dataset\n    return len(self.question)\n\n  def __getitem__(self,item):             # This method retrieves the item at the specified index item. \n\n    question = str(self.question[item])\n    question = ''.join(question.split())\n\n    answer = str(self.answer[item])\n    answer = ''.join(answer.split())\n\n    input_tokenize = self.tokenizer(      \n            question,\n            add_special_tokens=True,\n            max_length=self.input_max_len,\n            padding = 'max_length',\n            truncation = True,\n            return_attention_mask=True,\n            return_tensors=\"pt\"\n        )\n    output_tokenize = self.tokenizer(\n            answer,\n            add_special_tokens=True,\n            max_length=self.output_max_len,\n            padding = 'max_length',\n            truncation = True,\n            return_attention_mask=True,\n            return_tensors=\"pt\"\n            \n        )\n    \n\n    input_ids = input_tokenize[\"input_ids\"].flatten()\n    attention_mask = input_tokenize[\"attention_mask\"].flatten()\n    labels = output_tokenize['input_ids'].flatten()\n\n    out = {\n            'question':question,      \n            'answer':answer,\n            'input_ids': input_ids,\n            'attention_mask':attention_mask,\n            'target':labels\n        }\n        \n    return out      ","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:41.261492Z","iopub.execute_input":"2024-05-31T13:00:41.262317Z","iopub.status.idle":"2024-05-31T13:00:41.275084Z","shell.execute_reply.started":"2024-05-31T13:00:41.262277Z","shell.execute_reply":"2024-05-31T13:00:41.273897Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class T5DataLoad(pl.LightningDataModule):\n    \n    def __init__(self,df_train,df_test):\n        super().__init__()\n        self.df_train = df_train\n        self.df_test = df_test\n        self.tokenizer = tokenizer\n        self.input_max_len = INPUT_MAX_LEN\n        self.out_max_len = OUTPUT_MAX_LEN\n    \n    def setup(self, stage=None):\n        \n        self.train_data = T5Dataset(\n            question = self.df_train.question.values,\n            answer = self.df_train.answer.values\n        )\n        \n        self.valid_data = T5Dataset(\n            question = self.df_test.question.values,\n            answer = self.df_test.answer.values\n        )\n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(\n         self.train_data,\n         batch_size= TRAIN_BATCH_SIZE,\n         shuffle=True, \n         num_workers=2\n        )\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(\n        self.valid_data,\n        batch_size= VAL_BATCH_SIZE,\n        num_workers = 2\n        )","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:44.960264Z","iopub.execute_input":"2024-05-31T13:00:44.960694Z","iopub.status.idle":"2024-05-31T13:00:44.971102Z","shell.execute_reply.started":"2024-05-31T13:00:44.960659Z","shell.execute_reply":"2024-05-31T13:00:44.970056Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class T5Model(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict = True)\n\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        \n        output = self.model(\n        input_ids=input_ids, \n        attention_mask=attention_mask, \n        labels=labels\n        )\n        return output.loss, output.logits\n    \n    def training_step(self, batch, batch_idx):\n\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        labels= batch[\"target\"]\n        loss, logits = self(input_ids , attention_mask, labels)\n\n        \n        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n\n        return {'loss': loss}\n    \n    def validation_step(self, batch, batch_idx):\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        labels= batch[\"target\"]\n        loss, logits = self(input_ids, attention_mask, labels)\n\n        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n        \n        return {'val_loss': loss}\n\n    def configure_optimizers(self):\n        return AdamW(self.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:48.227979Z","iopub.execute_input":"2024-05-31T13:00:48.228874Z","iopub.status.idle":"2024-05-31T13:00:48.239416Z","shell.execute_reply.started":"2024-05-31T13:00:48.228834Z","shell.execute_reply":"2024-05-31T13:00:48.238329Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Final Training Step","metadata":{}},{"cell_type":"code","source":"df_train, df_test = train_test_split(data,test_size = 0.1, random_state=40)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:51.798571Z","iopub.execute_input":"2024-05-31T13:00:51.799635Z","iopub.status.idle":"2024-05-31T13:00:51.808944Z","shell.execute_reply.started":"2024-05-31T13:00:51.799593Z","shell.execute_reply":"2024-05-31T13:00:51.807992Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def run():\n    df_train, df_test = train_test_split(data,test_size = 0.15, random_state=40)\n    dataload = T5DataLoad(df_train,df_test)\n    dataload.setup()\n    device = DEVICE\n    model = T5Model()\n    model.to(device)\n    print(len(df_train))\n    checkpoint = ModelCheckpoint(\n        dirpath=\"/kaggle/working\",\n        filename='best-model',\n        save_top_k=2,\n        verbose=True,\n        monitor=\"val_loss\",\n        mode=\"min\"\n    )\n    trainer = pl.Trainer(\n        callbacks = checkpoint,\n        max_epochs= 10,\n        gpus=1,\n        accelerator=\"gpu\"\n    )\n    trainer.fit(model, dataload)\nrun()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:00:54.049502Z","iopub.execute_input":"2024-05-31T13:00:54.050501Z","iopub.status.idle":"2024-05-31T13:17:41.982456Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1678af88e26c4cee9d7c0cf2706e02e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ration_config.json\";:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5056855a8edf4bffab11791edee49ac9"}},"metadata":{}},{"name":"stdout","text":"22841\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85601635a39144998172b2fda364b8e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"train_model = T5Model.load_from_checkpoint('/kaggle/working/best-model.ckpt')\ntrain_model.freeze()\n\ndef generate_question(question):\n\n    inputs_encoding =  tokenizer(\n        question,\n        add_special_tokens=True,\n        max_length= INPUT_MAX_LEN,\n        padding = 'max_length',\n        truncation='only_first',\n        return_attention_mask=True,\n        return_tensors=\"pt\"\n        )\n\n    \n    generate_ids = train_model.model.generate(\n        input_ids = inputs_encoding[\"input_ids\"],\n        attention_mask = inputs_encoding[\"attention_mask\"],\n        max_length = INPUT_MAX_LEN,\n        num_beams = 4,\n        num_return_sequences = 1,\n        no_repeat_ngram_size=2,\n        early_stopping=True,\n        )\n\n    preds = [\n        tokenizer.decode(gen_id,\n        skip_special_tokens=True, \n        clean_up_tokenization_spaces=True)\n        for gen_id in generate_ids\n    ]\n\n    return \"\".join(preds)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T19:35:12.584408Z","iopub.execute_input":"2024-05-16T19:35:12.585649Z","iopub.status.idle":"2024-05-16T19:35:18.110294Z","shell.execute_reply.started":"2024-05-16T19:35:12.585599Z","shell.execute_reply":"2024-05-16T19:35:18.109359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"ques = \"I cannot pay for this product, cancel order 12345\"\nprint(\"Ques: \",ques)\nprint(\"BOT: \",generate_question(ques))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T20:03:12.246788Z","iopub.execute_input":"2024-05-16T20:03:12.247541Z","iopub.status.idle":"2024-05-16T20:03:14.818411Z","shell.execute_reply.started":"2024-05-16T20:03:12.247504Z","shell.execute_reply":"2024-05-16T20:03:14.817326Z"},"trusted":true},"execution_count":null,"outputs":[]}]}